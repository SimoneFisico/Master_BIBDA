{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Verbis Virtus - ETL\n",
    "## Create fact tables from data stored in PostgreSQL DBMS\n",
    "Some initial imports and functions definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2 as ps\n",
    "import math\n",
    "import os\n",
    "\n",
    "def get_data(conn, query):\n",
    "    results = []\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query)\n",
    "        for data in cursor.fetchall():\n",
    "            results.append(data)\n",
    "        cursor.close()\n",
    "        print(f'Num of rows fetched: {len(results)}')\n",
    "    except Exception as e:\n",
    "        print(f\"Exception: {e}\")\n",
    "    return results\n",
    "\n",
    "def get_col_names(conn, table_str):\n",
    "\n",
    "    col_names = []\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(f\"SELECT * FROM {table_str} LIMIT 0\")\n",
    "        for desc in cursor.description:\n",
    "            col_names.append(desc[0])        \n",
    "        cursor.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Exception: {e}\")\n",
    "\n",
    "    return col_names\n",
    "\n",
    "def get_df_data(conn, query_str, table_str):\n",
    "    col_names = get_col_names(conn, table_str)\n",
    "    results = get_data(conn, query_str)\n",
    "    df = pd.DataFrame(results, columns=col_names)\n",
    "    return df\n",
    "\n",
    "def distance_calculator(steps):\n",
    "    tot_distance = 0.0\n",
    "    for index, _ in steps.iterrows():\n",
    "        if index < steps.shape[0] -2:\n",
    "            x_diff = (steps.loc[index].posx - steps.loc[index+1].posx)\n",
    "            y_diff = (steps.loc[index].posy - steps.loc[index+1].posy)\n",
    "            distance = math.sqrt(x_diff**2+y_diff**2)\n",
    "            tot_distance = tot_distance + distance\n",
    "    return tot_distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to DB\n",
    "Pay attention to replace your data to create the right connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'postgres'\n",
    "password = 'testing'\n",
    "host = 'localhost'\n",
    "port = '54321'\n",
    "db_name = 'IVV'\n",
    "\n",
    "connection_string = f\"user='{user}' password='{password}' host='{host}' port='{port}' dbname='{db_name}'\"\n",
    "\n",
    "try:\n",
    "    conn = ps.connect(connection_string)\n",
    "    print(f\"Connection established: {conn}\")\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get tables names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT table_name\n",
    "    FROM information_schema.tables\n",
    "    WHERE table_schema = 'public'\n",
    "\"\"\")\n",
    "\n",
    "# Fetch all the table names\n",
    "table_names = cursor.fetchall()\n",
    "cursor.close()\n",
    "\n",
    "# Print the table names\n",
    "for table_name in table_names:\n",
    "    print(table_name[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List columns names from seleted table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'stg_ivv_analytics'\n",
    "col_names = get_col_names(conn, table_name)\n",
    "col_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get unique players IDs\n",
    "...and save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'stg_ivv_analytics'\n",
    "query_str = f\"SELECT DISTINCT player_id  FROM {table_name}\"\n",
    "players = get_data(conn, query_str)\n",
    "players_df = pd.DataFrame(players, columns=['player'])\n",
    "\n",
    "if not os.path.exists('fact/CSV'):\n",
    "    os.makedirs('fact/CSV')\n",
    "\n",
    "players_df.to_csv(f'./fact/CSV/players.csv')\n",
    "\n",
    "#players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "## Create dataset as CSV files for data visualization\n",
    "The JSON file (see below) seems to be too large for Tableau desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## limiting the number of players for testing\n",
    "# players = players[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'stg_ivv_analytics'\n",
    "\n",
    "i = 0\n",
    "row_index = 0\n",
    "sessions_df = pd.DataFrame()\n",
    "\n",
    "for player in players:\n",
    "    i = i + 1\n",
    "    print(f'Working on {i}/{len(players)}')\n",
    "    ## Create the DF to store all the steps to save as single CSV\n",
    "    all_steps = pd.DataFrame()\n",
    "\n",
    "    ## get the player_id\n",
    "    player_id = player[0]   \n",
    "\n",
    "    ## get user log from database\n",
    "    query_str = f\"SELECT * FROM {table_name} WHERE player_id ='{player_id}' ORDER BY session_id, log_id\"\n",
    "    rows = get_df_data(conn, query_str, table_name)\n",
    "\n",
    "    ## set real_time and game_time to 0.0 for event_type 'BeginLog'\n",
    "    rows.loc[rows.event_type =='BeginLog',['game_time','real_time']] = 0.0\n",
    "    ## working on single session\n",
    "    for session in rows.session_id.unique():\n",
    "        #print(row_index)\n",
    "        ## Create df and store some infos\n",
    "        session_df = pd.DataFrame(columns=['player','session','session_logs','map_info','max_real_time','max_game_time','distance'])\n",
    "        session_df.loc[row_index,'player'] = player_id\n",
    "        session_df.loc[row_index,'session']  = session\n",
    "\n",
    "        ## extract rows for current session\n",
    "        session_rows = rows[rows.session_id == session]\n",
    "\n",
    "        ## add data\n",
    "        map_info = session_rows[session_rows.event_type == 'BeginLog'].map_info.item()\n",
    "        session_df.loc[row_index,'session_logs'] = session_rows.shape[0]\n",
    "        session_df.loc[row_index,'map_info'] = map_info\n",
    "        session_df.loc[row_index,'max_real_time'] = session_rows.real_time.max()\n",
    "        session_df.loc[row_index,'max_game_time'] =session_rows.game_time.max()\n",
    "        \n",
    "        ## extract steps where positions are defined\n",
    "        steps = session_rows[~session_rows.position.isna()].reset_index()\n",
    "        steps['map_info'] = map_info\n",
    "        ## expand the x, y amd z position \n",
    "        steps[['posx','posy','posz']] = steps.position.str.split(',', expand=True)\n",
    "        steps[['posx','posy','posz']] = steps[['posx','posy','posz']].astype(float)\n",
    "        steps = steps.drop('position', axis=1)\n",
    "        ## expand rotation infos\n",
    "        steps[['pitch','yaw','roll']] = steps.rotation.str.split(',', expand=True)\n",
    "        steps[['pitch','yaw','roll']] = steps[['pitch','yaw','roll']].astype(float)\n",
    "        steps = steps.drop('rotation', axis=1)\n",
    "        ## expand the x, y amd z velocity \n",
    "        steps[['velx','vely','velz']] = steps.velocity.str.split(',', expand=True)\n",
    "        steps[['velx','vely','velz']] = steps[['velx','vely','velz']].astype(float)\n",
    "        steps = steps.drop('velocity', axis=1)\n",
    "\n",
    "        all_steps = pd.concat([all_steps, steps], ignore_index=True)\n",
    "\n",
    "        ## calculate total distanstance for the player in the session\n",
    "        session_df.loc[row_index,'distance'] = distance_calculator(steps)\n",
    "        sessions_df = pd.concat([sessions_df, session_df], ignore_index=True)\n",
    "        row_index = row_index + 1\n",
    "\n",
    "    if not os.path.exists('fact/CSV/players'):\n",
    "        os.makedirs('fact/CSV/players')\n",
    "    \n",
    "    all_steps.to_csv(f'./fact/CSV/players/player_{player_id}.csv')\n",
    "\n",
    "sessions_df.to_csv(f'./fact/CSV/sessions.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a CSV with the all sessions details\n",
    "This is needed for Tableau data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "folder = os.fsencode('./fact/CSV/players')\n",
    "full_sessions_dataset = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    filename = os.fsdecode(file)\n",
    "    print(filename)\n",
    "    if filename.endswith(\".csv\") : \n",
    "        print(f'Working on {filename}')\n",
    "        dataset = pd.read_csv(f'./fact/CSV/players/{filename}')\n",
    "        full_sessions_dataset = pd.concat([full_sessions_dataset, dataset], ignore_index=True)\n",
    "        print(f'Dataset shape {full_sessions_dataset.shape}')\n",
    "        print('-*'*10)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "full_sessions_dataset.to_csv(f'./fact/CSV/sessions_details.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataset as a Dictionary to store as a JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'stg_ivv_analytics'\n",
    "\n",
    "data_list = []\n",
    "i = 0\n",
    "for player in players:\n",
    "    i = i + 1\n",
    "    print(f'Working on {i}/{len(players)}')\n",
    "    ## get the player_id\n",
    "    player_id = player[0]\n",
    "\n",
    "    ## set some user infos into the user dictionary\n",
    "    user_dict = {}\n",
    "    user_dict['player'] = player_id\n",
    "    user_dict['sessions'] = []\n",
    "\n",
    "    ## get user log from database\n",
    "    query_str = f\"SELECT * FROM {table_name} WHERE player_id ='{player_id}' ORDER BY session_id, log_id\"\n",
    "    rows = get_df_data(conn, query_str, table_name)\n",
    "    user_dict['total_logs'] = rows.shape[0]\n",
    "    ## set real_time and game_time to 0.0 for event_type 'BeginLog'\n",
    "    rows.loc[rows.event_type =='BeginLog',['game_time','real_time']] = 0.0\n",
    "    \n",
    "    ## working on single session\n",
    "    for session in rows.session_id.unique():\n",
    "        session_dict = {}\n",
    "        ## extract rows for current session\n",
    "        session_rows = rows[rows.session_id == session]\n",
    "\n",
    "        ## add some infos to dict\n",
    "        session_dict['id'] = session\n",
    "        session_dict['session_logs'] = session_rows.shape[0]\n",
    "        session_dict['map_info'] = session_rows[session_rows.event_type == 'BeginLog'].map_info.item()\n",
    "        session_dict['max_real_time'] = session_rows.real_time.max()\n",
    "        session_dict['max_game_time'] =session_rows.game_time.max()\n",
    "        \n",
    "        ## extract steps where positions are defined\n",
    "        steps = session_rows[~session_rows.position.isna()].reset_index()\n",
    "        ## expand the x, y amd z position \n",
    "        steps[['posx','posy','posz']] = steps.position.str.split(',', expand=True)\n",
    "        steps[['posx','posy','posz']] = steps[['posx','posy','posz']].astype(float)\n",
    "        steps = steps.drop('position', axis=1)\n",
    "        ## expand rotation infos\n",
    "        steps[['pitch','yaw','roll']] = steps.rotation.str.split(',', expand=True)\n",
    "        steps[['pitch','yaw','roll']] = steps[['pitch','yaw','roll']].astype(float)\n",
    "        steps = steps.drop('rotation', axis=1)\n",
    "        ## expand the x, y amd z velocity \n",
    "        steps[['velx','vely','velz']] = steps.velocity.str.split(',', expand=True)\n",
    "        steps[['velx','vely','velz']] = steps[['velx','vely','velz']].astype(float)\n",
    "        steps = steps.drop('velocity', axis=1)\n",
    "\n",
    "        ## extract other logs where positions are not defined\n",
    "        other_log = session_rows[session_rows.position.isna()].reset_index()\n",
    "        other_log = other_log.drop('health', axis=1)\n",
    "        session_dict['other_logs']= []\n",
    "        for log in other_log.to_dict('records'):\n",
    "            session_dict['other_logs'].append( {k: v for k, v in log.items() if v is not None})\n",
    "\n",
    "        ## set the steps and other logs under the session onject\n",
    "        session_dict['steps'] = []\n",
    "        for step in steps.to_dict('records'):\n",
    "            session_dict['steps'].append({k: v for k, v in step.items() if v is not None})\n",
    "\n",
    "        ## calculate total distanstance for the player in the session\n",
    "        session_dict['distance'] = distance_calculator(steps)\n",
    "\n",
    "        user_dict['sessions'].append(session_dict)\n",
    "\n",
    "    data_list.append(user_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the dataset to a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        if isinstance(obj, pd.Timestamp):\n",
    "            return obj.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        if isinstance(obj, type(pd.NaT)):\n",
    "            return str('')\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "json_str = json.dumps(data_list, cls=NpEncoder)\n",
    "\n",
    "if not os.path.exists('fact'):\n",
    "    os.makedirs('fact')\n",
    "\n",
    "with open(\"./fact/ivv_fact.json\", \"w+\") as f:\n",
    "    json.dump(data_list, f, indent=4, sort_keys=False, cls=NpEncoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analyticenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
